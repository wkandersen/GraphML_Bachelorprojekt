{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5416271, 5416271)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "# Set working directory\n",
    "\n",
    "try:\n",
    "    data_train = pd.read_csv('dataset/ogbn_mag/split/time/paper/train.csv.gz', compression='gzip',header = None)\n",
    "    data_valid = pd.read_csv('dataset/ogbn_mag/split/time/paper/valid.csv.gz', compression='gzip',header = None)\n",
    "    data_test = pd.read_csv('dataset/ogbn_mag/split/time/paper/test.csv.gz', compression='gzip',header = None)\n",
    "except FileNotFoundError:\n",
    "    os.chdir(\"..\")\n",
    "    data_train = pd.read_csv('dataset/ogbn_mag/split/time/paper/train.csv.gz', compression='gzip',header = None)\n",
    "    data_valid = pd.read_csv('dataset/ogbn_mag/split/time/paper/valid.csv.gz', compression='gzip',header = None)\n",
    "    data_test = pd.read_csv('dataset/ogbn_mag/split/time/paper/test.csv.gz', compression='gzip',header = None)\n",
    "\n",
    "data, _ = torch.load(r\"dataset/ogbn_mag/processed/geometric_data_processed.pt\", weights_only=False)\n",
    "\n",
    "# Extract edges for \"paper\" -> \"cites\" -> \"paper\"\n",
    "paper_c_paper = data.edge_index_dict[('paper', 'cites', 'paper')]\n",
    "\n",
    "# Unique paper IDs to keep (Ensure it's a PyTorch tensor)\n",
    "nums_valid = torch.tensor(data_valid[0])\n",
    "nums_test = torch.tensor(data_test[0])\n",
    "nums_train = torch.tensor(data_train[0])\n",
    "\n",
    "mask_train = torch.isin(paper_c_paper[0], nums_train) | torch.isin(paper_c_paper[1], nums_train)\n",
    "mask_valid = torch.isin(paper_c_paper[0], nums_valid) | torch.isin(paper_c_paper[1], nums_valid)\n",
    "mask_test = torch.isin(paper_c_paper[0], nums_test) | torch.isin(paper_c_paper[1], nums_test)\n",
    "\n",
    "paper_c_paper_train = paper_c_paper.clone()\n",
    "paper_c_paper_valid = paper_c_paper.clone()\n",
    "paper_c_paper_test = paper_c_paper.clone()\n",
    "\n",
    "# Combine the conditions into a single mask that selects only the train edges\n",
    "mask_train_done = mask_train & ~mask_valid & ~mask_test\n",
    "mask_valid_done = mask_valid & ~mask_test\n",
    "\n",
    "# Apply the combined mask to paper_c_paper_train\n",
    "paper_c_paper_train = paper_c_paper_train[:, mask_train_done]\n",
    "paper_c_paper_valid = paper_c_paper_valid[:, mask_valid_done]\n",
    "paper_c_paper_test = paper_c_paper_test[:, mask_test]\n",
    "\n",
    "len(paper_c_paper_train[1]) + len(paper_c_paper_valid[1]) + len(paper_c_paper_test[1]), paper_c_paper.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7145660, 7145660)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_w_paper = data.edge_index_dict[('author', 'writes', 'paper')]\n",
    "\n",
    "author_w_paper_train = author_w_paper.clone()\n",
    "author_w_paper_valid = author_w_paper.clone()\n",
    "author_w_paper_test = author_w_paper.clone()\n",
    "\n",
    "# Unique paper IDs to keep (Ensure it's a PyTorch tensor)\n",
    "nums_valid = torch.tensor(data_valid[0])\n",
    "nums_test = torch.tensor(data_test[0])\n",
    "nums_train = torch.tensor(data_train[0])\n",
    "\n",
    "mask_train = torch.isin(author_w_paper[1], nums_train)\n",
    "mask_valid = torch.isin(author_w_paper[1], nums_valid)\n",
    "mask_test = torch.isin(author_w_paper[1], nums_test)\n",
    "\n",
    "# Combine the conditions into a single mask that selects only the train edges\n",
    "mask_train_done = mask_train & ~mask_valid & ~mask_test\n",
    "mask_valid_done = mask_valid & ~mask_test\n",
    "\n",
    "# Apply the combined mask to paper_c_paper_train\n",
    "author_w_paper_train = author_w_paper_train[:, mask_train_done]\n",
    "author_w_paper_valid = author_w_paper_valid[:, mask_valid_done]\n",
    "author_w_paper_test = author_w_paper_test[:, mask_test]\n",
    "\n",
    "len(author_w_paper_train[1]) + len(author_w_paper_valid[1]) + len(author_w_paper_test[1]), author_w_paper.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7505078, 7505078)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_t_field = data.edge_index_dict[('paper', 'has_topic', 'field_of_study')]\n",
    "\n",
    "paper_t_field_train = paper_t_field.clone()\n",
    "paper_t_field_valid = paper_t_field.clone()\n",
    "paper_t_field_test = paper_t_field.clone()\n",
    "\n",
    "# Unique paper IDs to keep (Ensure it's a PyTorch tensor)\n",
    "nums_valid = torch.tensor(data_valid[0])\n",
    "nums_test = torch.tensor(data_test[0])\n",
    "nums_train = torch.tensor(data_train[0])\n",
    "\n",
    "mask_train = torch.isin(paper_t_field[0], nums_train)\n",
    "mask_valid = torch.isin(paper_t_field[0], nums_valid)\n",
    "mask_test = torch.isin(paper_t_field[0], nums_test)\n",
    "\n",
    "# Combine the conditions into a single mask that selects only the train edges\n",
    "mask_train_done = mask_train & ~mask_valid & ~mask_test\n",
    "mask_valid_done = mask_valid & ~mask_test\n",
    "\n",
    "# Apply the combined mask to paper_c_paper_train\n",
    "paper_t_field_train = paper_t_field_train[:, mask_train_done]\n",
    "paper_t_field_valid = paper_t_field_valid[:, mask_valid_done]\n",
    "paper_t_field_test = paper_t_field_test[:, mask_test]\n",
    "\n",
    "len(paper_t_field_train[1]) + len(paper_t_field_valid[1]) + len(paper_t_field_test[1]), paper_t_field.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(\n",
       "  num_nodes_dict={\n",
       "    author=1134649,\n",
       "    field_of_study=59965,\n",
       "    institution=8740,\n",
       "    paper=736389,\n",
       "  },\n",
       "  edge_index_dict={\n",
       "    (author, affiliated_with, institution)=[2, 1043998],\n",
       "    (author, writes, paper)=[2, 7145660],\n",
       "    (paper, cites, paper)=[2, 5416271],\n",
       "    (paper, has_topic, field_of_study)=[2, 7505078],\n",
       "  },\n",
       "  x_dict={ paper=[736389, 128] },\n",
       "  node_year={ paper=[736389, 1] },\n",
       "  edge_reltype={\n",
       "    (author, affiliated_with, institution)=[1043998, 1],\n",
       "    (author, writes, paper)=[7145660, 1],\n",
       "    (paper, cites, paper)=[5416271, 1],\n",
       "    (paper, has_topic, field_of_study)=[7505078, 1],\n",
       "  },\n",
       "  y_dict={ paper=[736389, 1] }\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42937/2906774071.py:3: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  paper_c_paper_train_0 = np.array(paper_c_paper_train[0])\n",
      "/tmp/ipykernel_42937/2906774071.py:4: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  paper_c_paper_train_1 = np.array(paper_c_paper_train[1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3879967, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "paper_c_paper_train_0 = np.array(paper_c_paper_train[0])\n",
    "paper_c_paper_train_1 = np.array(paper_c_paper_train[1])\n",
    "\n",
    "datamatrix = np.column_stack([\n",
    "    (paper_c_paper_train_0 == np.arange(len(paper_c_paper_train_0))).astype(int), paper_c_paper_train_0, paper_c_paper_train_1, \n",
    "])\n",
    "\n",
    "# np.argwhere(d[0, 1] == 0)\n",
    "len(np.argwhere(datamatrix[:, 0] == 0)), len(np.argwhere(datamatrix[:, 0] == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3879968"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paper_c_paper_train_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([     0,      2,      4, ..., 736386, 736387, 736388],\n",
       "       shape=(512046,)),\n",
       " array([     0,      1,      2, ..., 736383, 736386, 736388],\n",
       "       shape=(505777,)))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(paper_c_paper_train_0), np.unique(paper_c_paper_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     0,      0,      0,  ..., 736388, 736388, 736388],\n",
       "        [    88,  27449, 121051,  ..., 421711, 427339, 439864]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_c_paper_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3879968, 3879968)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paper_c_paper_train[0]), len(paper_c_paper_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42937/195433624.py:38: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
      "  citation_matrix = torch.sparse_coo_tensor((citation_matrix_coo.row, citation_matrix_coo.col), citation_matrix_coo.data)\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Could not run 'aten::as_strided' with arguments from the 'SparseCPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::as_strided' is only available for these backends: [CPU, CUDA, Meta, QuantizedCPU, QuantizedCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradMeta, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastMPS, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nCPU: registered at /pytorch/build/aten/src/ATen/RegisterCPU.cpp:30477 [kernel]\nCUDA: registered at /pytorch/build/aten/src/ATen/RegisterCUDA.cpp:44731 [kernel]\nMeta: registered at /pytorch/build/aten/src/ATen/RegisterMeta.cpp:27006 [kernel]\nQuantizedCPU: registered at /pytorch/build/aten/src/ATen/RegisterQuantizedCPU.cpp:955 [kernel]\nQuantizedCUDA: registered at /pytorch/build/aten/src/ATen/RegisterQuantizedCUDA.cpp:463 [kernel]\nBackendSelect: fallthrough registered at /pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:194 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:503 [backend fallback]\nFunctionalize: registered at /pytorch/build/aten/src/ATen/RegisterFunctionalization_0.cpp:23301 [kernel]\nNamed: fallthrough registered at /pytorch/aten/src/ATen/core/NamedRegistrations.cpp:11 [kernel]\nConjugate: fallthrough registered at /pytorch/aten/src/ATen/ConjugateFallback.cpp:21 [kernel]\nNegative: fallthrough registered at /pytorch/aten/src/ATen/native/NegateFallback.cpp:22 [kernel]\nZeroTensor: registered at /pytorch/build/aten/src/ATen/RegisterZeroTensor.cpp:165 [kernel]\nADInplaceOrView: registered at /pytorch/torch/csrc/autograd/generated/ADInplaceOrViewType_0.cpp:4942 [kernel]\nAutogradOther: registered at /pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:18082 [autograd kernel]\nAutogradCPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:18082 [autograd kernel]\nAutogradCUDA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:18082 [autograd kernel]\nAutogradHIP: registered at /pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:18082 [autograd kernel]\nAutogradXLA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:18082 [autograd kernel]\nAutogradMPS: registered at /pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:18082 [autograd kernel]\nAutogradIPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:18082 [autograd kernel]\nAutogradXPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:18082 [autograd kernel]\nAutogradHPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:18082 [autograd kernel]\nAutogradVE: registered at /pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:18082 [autograd kernel]\nAutogradLazy: registered at /pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:18082 [autograd kernel]\nAutogradMTIA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:18082 [autograd kernel]\nAutogradPrivateUse1: registered at /pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:18082 [autograd kernel]\nAutogradPrivateUse2: registered at /pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:18082 [autograd kernel]\nAutogradPrivateUse3: registered at /pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:18082 [autograd kernel]\nAutogradMeta: registered at /pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:18082 [autograd kernel]\nAutogradNestedTensor: registered at /pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:18082 [autograd kernel]\nTracer: registered at /pytorch/torch/csrc/autograd/generated/TraceType_0.cpp:17100 [kernel]\nAutocastCPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:322 [backend fallback]\nAutocastXPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:465 [backend fallback]\nAutocastMPS: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:209 [backend fallback]\nAutocastCUDA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:165 [backend fallback]\nFuncTorchBatched: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:735 [kernel]\nBatchedNestedTensor: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]\nBatched: registered at /pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1079 [kernel]\nVmapMode: fallthrough registered at /pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:207 [backend fallback]\nPythonTLSSnapshot: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:202 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:499 [backend fallback]\nPreDispatch: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:206 [backend fallback]\nPythonDispatcher: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:198 [backend fallback]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 39\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# If you want to save this matrix to disk (e.g., in HDF5 format), you can do so:\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# import h5py\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# with h5py.File('citation_matrix.h5', 'w') as f:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m \n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# use in pytorch\u001b[39;00m\n\u001b[1;32m     38\u001b[0m citation_matrix \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msparse_coo_tensor((citation_matrix_coo\u001b[38;5;241m.\u001b[39mrow, citation_matrix_coo\u001b[38;5;241m.\u001b[39mcol), citation_matrix_coo\u001b[38;5;241m.\u001b[39mdata)\n\u001b[0;32m---> 39\u001b[0m citation_matrix[:, \u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Could not run 'aten::as_strided' with arguments from the 'SparseCPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::as_strided' is only available for these backends: [CPU, CUDA, Meta, QuantizedCPU, QuantizedCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradMeta, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastMPS, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nCPU: registered at /pytorch/build/aten/src/ATen/RegisterCPU.cpp:30477 [kernel]\nCUDA: registered at /pytorch/build/aten/src/ATen/RegisterCUDA.cpp:44731 [kernel]\nMeta: registered at /pytorch/build/aten/src/ATen/RegisterMeta.cpp:27006 [kernel]\nQuantizedCPU: registered at /pytorch/build/aten/src/ATen/RegisterQuantizedCPU.cpp:955 [kernel]\nQuantizedCUDA: registered at /pytorch/build/aten/src/ATen/RegisterQuantizedCUDA.cpp:463 [kernel]\nBackendSelect: fallthrough registered at /pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:194 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:503 [backend fallback]\nFunctionalize: registered at /pytorch/build/aten/src/ATen/RegisterFunctionalization_0.cpp:23301 [kernel]\nNamed: fallthrough registered at /pytorch/aten/src/ATen/core/NamedRegistrations.cpp:11 [kernel]\nConjugate: fallthrough registered at /pytorch/aten/src/ATen/ConjugateFallback.cpp:21 [kernel]\nNegative: fallthrough registered at /pytorch/aten/src/ATen/native/NegateFallback.cpp:22 [kernel]\nZeroTensor: registered at /pytorch/build/aten/src/ATen/RegisterZeroTensor.cpp:165 [kernel]\nADInplaceOrView: registered at /pytorch/torch/csrc/autograd/generated/ADInplaceOrViewType_0.cpp:4942 [kernel]\nAutogradOther: registered at /pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:18082 [autograd kernel]\nAutogradCPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:18082 [autograd kernel]\nAutogradCUDA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:18082 [autograd kernel]\nAutogradHIP: registered at /pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:18082 [autograd kernel]\nAutogradXLA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:18082 [autograd kernel]\nAutogradMPS: registered at /pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:18082 [autograd kernel]\nAutogradIPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:18082 [autograd kernel]\nAutogradXPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:18082 [autograd kernel]\nAutogradHPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:18082 [autograd kernel]\nAutogradVE: registered at /pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:18082 [autograd kernel]\nAutogradLazy: registered at /pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:18082 [autograd kernel]\nAutogradMTIA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:18082 [autograd kernel]\nAutogradPrivateUse1: registered at /pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:18082 [autograd kernel]\nAutogradPrivateUse2: registered at /pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:18082 [autograd kernel]\nAutogradPrivateUse3: registered at /pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:18082 [autograd kernel]\nAutogradMeta: registered at /pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:18082 [autograd kernel]\nAutogradNestedTensor: registered at /pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:18082 [autograd kernel]\nTracer: registered at /pytorch/torch/csrc/autograd/generated/TraceType_0.cpp:17100 [kernel]\nAutocastCPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:322 [backend fallback]\nAutocastXPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:465 [backend fallback]\nAutocastMPS: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:209 [backend fallback]\nAutocastCUDA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:165 [backend fallback]\nFuncTorchBatched: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:735 [kernel]\nBatchedNestedTensor: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]\nBatched: registered at /pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1079 [kernel]\nVmapMode: fallthrough registered at /pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:207 [backend fallback]\nPythonTLSSnapshot: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:202 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:499 [backend fallback]\nPreDispatch: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:206 [backend fallback]\nPythonDispatcher: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:198 [backend fallback]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "import torch\n",
    "\n",
    "# Example citation data: Replace with your actual data\n",
    "# For example:\n",
    "# paper_ids = [0, 88, 27449, 121051, ...]  # Citing papers\n",
    "# cited_ids = [88, 27449, 121051, ..., 421711, 427339, 439864]  # Cited papers\n",
    "\n",
    "# Example tensor as you mentioned (2 rows, multiple columns)\n",
    "# tensor[0] represents paper_ids (papers that cite others)\n",
    "# tensor[1] represents cited paper_ids (papers being cited)\n",
    "tensor = paper_c_paper_train \n",
    "\n",
    "# Extract the data\n",
    "paper_ids = tensor[0].numpy()  # Citing papers\n",
    "cited_ids = tensor[1].numpy()  # Cited papers\n",
    "\n",
    "# Create a sparse matrix in COO format:\n",
    "citation_values = np.ones(len(paper_ids))  # All citations will have value 1\n",
    "\n",
    "# Create the sparse matrix with the correct shape\n",
    "citation_matrix_coo = coo_matrix((citation_values, (paper_ids, cited_ids)), shape=(max(paper_ids) + 1, max(cited_ids) + 1))\n",
    "\n",
    "# Now you have a sparse matrix with 3 columns (paper_id, cited_paper_id, 1 for citation)\n",
    "# Optionally, you can convert it to CSR format for better performance:\n",
    "citation_matrix_csr = citation_matrix_coo.tocsr()\n",
    "\n",
    "# If you want to save this matrix to disk (e.g., in HDF5 format), you can do so:\n",
    "# import h5py\n",
    "# with h5py.File('citation_matrix.h5', 'w') as f:\n",
    "#     f.create_dataset('rows', data=citation_matrix_coo.row)\n",
    "#     f.create_dataset('cols', data=citation_matrix_coo.col)\n",
    "#     f.create_dataset('data', data=citation_matrix_coo.data)\n",
    "\n",
    "\n",
    "# use in pytorch\n",
    "citation_matrix = torch.sparse_coo_tensor((citation_matrix_coo.row, citation_matrix_coo.col), citation_matrix_coo.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class LossFunction:\n",
    "    def __init__(self, alpha=1.0, eps=1e-8, use_regularization=False, lam=0.001):\n",
    "        \"\"\"\n",
    "        Initialize the loss function with given parameters.\n",
    "        \n",
    "        Args:\n",
    "            alpha (float): Scaling parameter for edge probability.\n",
    "            eps (float): Small value to prevent log(0).\n",
    "            use_regularization (bool): Whether to include Gaussian regularization.\n",
    "        \"\"\"\n",
    "        self.alpha = alpha\n",
    "        self.eps = eps\n",
    "        self.lam = lam\n",
    "        self.use_regularization = use_regularization\n",
    "\n",
    "    def edge_probability(self, z_i, z_j):\n",
    "        \"\"\"Compute the probability of an edge existing between two embeddings.\"\"\"\n",
    "        dist = torch.norm(z_i - z_j) ** 2  # Squared Euclidean distance\n",
    "        return 1 / (1 + torch.exp(-self.alpha + dist))  # Logistic function\n",
    "\n",
    "    def link_loss(self, label, z_u, z_v):\n",
    "        \"\"\"Compute the loss for a single edge.\"\"\"\n",
    "        prob = self.edge_probability(z_u, z_v)\n",
    "        prob = torch.clamp(prob, self.eps, 1 - self.eps)  # Numerical stability\n",
    "\n",
    "        return label.float() * torch.log(prob) + (1 - label.float()) * torch.log(1 - prob)\n",
    "\n",
    "    def compute_loss(self, z, datamatrix_tensor):\n",
    "        \"\"\"Compute the total loss for the dataset using sparse tensor.\"\"\"\n",
    "        \n",
    "        # Extract indices and values from the sparse tensor\n",
    "        indices = datamatrix_tensor.coalesce().indices()  # Shape: [2, nnz]\n",
    "        values = datamatrix_tensor.coalesce().values()    # Shape: [nnz]\n",
    "        \n",
    "        # Assume the indices are in the form of (u_idx, v_idx) pairs\n",
    "        u_idx = indices[0]  # The citing papers\n",
    "        v_idx = indices[1]  # The cited papers\n",
    "        \n",
    "        # Compute the link loss for the pairs (u_idx, v_idx) using vectorized operations\n",
    "        # self.link_loss should support batch operations for efficiency\n",
    "        losses = self.link_loss(values, z[u_idx], z[v_idx])\n",
    "        \n",
    "        # Sum the losses and compute the final loss\n",
    "        sum_loss = losses.sum()  # Sum over all citation events\n",
    "        loss = -sum_loss / len(values)  # Divide by the number of non-zero values (citations)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "\n",
    "# loss_fn = LossFunction(alpha=1.0, use_regularization=True)\n",
    "# loss_value = loss_fn.compute_loss(z, datamatrix_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "tensor(88)\n",
      "tensor(1., dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(citation_matrix.coalesce().indices()[0][0])\n",
    "print(citation_matrix.coalesce().indices()[1][0])\n",
    "print(citation_matrix.coalesce().values()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = nan\n",
      "Epoch 1: Loss = nan\n",
      "Epoch 2: Loss = nan\n",
      "Epoch 3: Loss = nan\n",
      "Epoch 4: Loss = nan\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 2\n",
    "node_embeddings = torch.nn.Embedding(len(paper_c_paper_train_0), embedding_dim)\n",
    "\n",
    "\n",
    "loss_function = LossFunction(alpha=1.0, eps=1e-10, use_regularization=False)\n",
    "\n",
    "optimizer = torch.optim.Adam(node_embeddings.parameters(), lr=0.01)\n",
    "\n",
    "alpha = 3\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    z = node_embeddings.weight  # Get embeddings\n",
    "    loss = loss_function.compute_loss(z, citation_matrix)  # Compute loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch}: Loss = {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    88,  27449, 121051, 151667, 308499])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_c_paper_train_1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    28, 333019])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_c_paper_train[:,88]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 6, 7]])\n",
      "tensor(186851)\n"
     ]
    }
   ],
   "source": [
    "print(np.argwhere(paper_c_paper_train[0] == 2))\n",
    "print(paper_c_paper_train[1][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3879968 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3879968/3879968 [00:57<00:00, 67341.46it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m paper_c_paper_train[\u001b[38;5;241m0\u001b[39m][i] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      6\u001b[0m     datamatrix\u001b[38;5;241m.\u001b[39mappend([paper_c_paper_train[\u001b[38;5;241m0\u001b[39m][i], paper_c_paper_train[\u001b[38;5;241m1\u001b[39m][i], label])\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28mprint\u001b[39m(datamatrix)\n",
      "File \u001b[0;32m~/.conda/envs/Bachelorprojekt/lib/python3.12/site-packages/torch/_tensor.py:568\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    565\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__repr__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents\n\u001b[1;32m    566\u001b[0m     )\n\u001b[1;32m    567\u001b[0m \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[0;32m--> 568\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_tensor_str\u001b[38;5;241m.\u001b[39m_str(\u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents)\n",
      "File \u001b[0;32m~/.conda/envs/Bachelorprojekt/lib/python3.12/site-packages/torch/_tensor_str.py:704\u001b[0m, in \u001b[0;36m_str\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(), torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39m_python_dispatch\u001b[38;5;241m.\u001b[39m_disable_current_modes():\n\u001b[1;32m    703\u001b[0m     guard \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_DisableFuncTorch()\n\u001b[0;32m--> 704\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _str_intern(\u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents)\n",
      "File \u001b[0;32m~/.conda/envs/Bachelorprojekt/lib/python3.12/site-packages/torch/_tensor_str.py:583\u001b[0m, in \u001b[0;36m_str_intern\u001b[0;34m(inp, tensor_contents)\u001b[0m\n\u001b[1;32m    578\u001b[0m         strs \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    579\u001b[0m             indented_str(\u001b[38;5;28mstr\u001b[39m(t), indent \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    580\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39maten\u001b[38;5;241m.\u001b[39munbind\u001b[38;5;241m.\u001b[39mint(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    581\u001b[0m         )\n\u001b[1;32m    582\u001b[0m         tensor_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mstrs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_is_functional_tensor(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    584\u001b[0m     prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_to_functional_tensor(\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    585\u001b[0m     tensor_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrepr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_from_functional_tensor(\u001b[38;5;28mself\u001b[39m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# creating datamatrix where 1 if link 0 if not, also add the 1st and 2nd column to the datamatrix\n",
    "from tqdm import tqdm\n",
    "datamatrix = []\n",
    "for i in tqdm(range(len(paper_c_paper_train[0]))):\n",
    "    label = 1 if i == paper_c_paper_train[0][i] else 0\n",
    "    datamatrix.append([paper_c_paper_train[0][i], paper_c_paper_train[1][i], label])\n",
    "\n",
    "print(datamatrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bachelorprojekt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
