{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "389570e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f392c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random   \n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class mini_batches_fast:\n",
    "    def __init__(self, data, unique_list, sample_size, edge_type, full_data, citation_dict, all_papers):\n",
    "        self.data = data\n",
    "        self.sample_size = sample_size\n",
    "        self.edge_type = edge_type\n",
    "        self.unique_list = unique_list\n",
    "        self.full_data = full_data\n",
    "        self.device = self.data.device if isinstance(self.data, torch.Tensor) else torch.device(\"cpu\")\n",
    "        self.citation_dict = citation_dict\n",
    "        self.all_papers = all_papers\n",
    "        self.remaining_papers = set(all_papers)\n",
    "        self.set_unique_list(unique_list)  # initialize tensor once\n",
    "\n",
    "    \n",
    "    def set_unique_list(self, unique_list):\n",
    "        if isinstance(unique_list, torch.Tensor):\n",
    "            self.unique_tensor = unique_list.to(self.device)\n",
    "        else:\n",
    "            self.unique_tensor = torch.tensor(unique_list, dtype=torch.long, device=self.device)\n",
    "\n",
    "    def get_batch(self):\n",
    "        unique_tensor = self.unique_tensor\n",
    "\n",
    "        if len(unique_tensor) < self.sample_size:\n",
    "            sample_tensor = unique_tensor\n",
    "            sample_tensor_sorted, _ = sample_tensor.sort()\n",
    "            idx = torch.searchsorted(sample_tensor_sorted, self.data[0])\n",
    "            idx = idx.clamp(max=sample_tensor_sorted.size(0) - 1)\n",
    "            mask = sample_tensor_sorted[idx] == self.data[0]\n",
    "            filtered_data = self.data[:, mask]\n",
    "            return filtered_data, sample_tensor.tolist(), []\n",
    "\n",
    "        # Efficient random sample and sort once\n",
    "        rand_idx = torch.randperm(len(unique_tensor), device=self.device)[:self.sample_size]\n",
    "        sample_tensor = unique_tensor[rand_idx]\n",
    "        sample_tensor_sorted, _ = sample_tensor.sort()\n",
    "\n",
    "        # Compute membership using searchsorted\n",
    "        idx = torch.searchsorted(sample_tensor_sorted, unique_tensor)\n",
    "        idx = idx.clamp(max=sample_tensor_sorted.size(0) - 1)\n",
    "        isin_mask = sample_tensor_sorted[idx] == unique_tensor\n",
    "        remaining_tensor = unique_tensor[~isin_mask]\n",
    "\n",
    "        # Filter edges\n",
    "        idx = torch.searchsorted(sample_tensor_sorted, self.data[0])\n",
    "        idx = idx.clamp(max=sample_tensor_sorted.size(0) - 1)\n",
    "        mask = sample_tensor_sorted[idx] == self.data[0]\n",
    "        filtered_data = self.data[:, mask]\n",
    "\n",
    "        return filtered_data, sample_tensor.tolist(), remaining_tensor\n",
    "    \n",
    "    def data_matrix(self):\n",
    "        data = self.full_data\n",
    "        edge_entities = {\n",
    "            'paper': 0,\n",
    "            'author': 1,\n",
    "            'institution': 2,\n",
    "            'field_of_study': 3,\n",
    "            'venue': 4,\n",
    "        }\n",
    "\n",
    "        tensor, random_sample, unique_tensor = self.get_batch()\n",
    "\n",
    "        if tensor.shape[1] == 0:\n",
    "            result_tensor = torch.empty((0, 5), dtype=torch.long, device=self.device)\n",
    "        else:\n",
    "            edge_type1 = edge_entities[self.edge_type[0]]\n",
    "            edge_type2 = edge_entities[self.edge_type[2]]\n",
    "            ones = torch.ones(tensor.shape[1], device=self.device, dtype=torch.long)\n",
    "            result_tensor = torch.stack([\n",
    "                ones,\n",
    "                tensor[0, :],\n",
    "                tensor[1, :],\n",
    "                torch.full((tensor.shape[1],), edge_type1, device=self.device),\n",
    "                torch.full((tensor.shape[1],), edge_type2, device=self.device)\n",
    "            ], dim=1).long()\n",
    "\n",
    "        paper_venues = data['y_dict']['paper']\n",
    "        random_sample_tensor = torch.tensor(random_sample, device=self.device).long()\n",
    "        venue_targets = paper_venues[random_sample_tensor]\n",
    "\n",
    "        venues_tensor = torch.stack([\n",
    "            torch.ones(len(random_sample), device=self.device, dtype=torch.long),\n",
    "            random_sample_tensor,\n",
    "            venue_targets.flatten(),\n",
    "            torch.full((len(random_sample),), edge_type1, device=self.device),\n",
    "            torch.full((len(random_sample),), edge_entities['venue'], device=self.device)\n",
    "        ], dim=1).long()\n",
    "\n",
    "        if tensor.shape[1] > 0:\n",
    "            unique_targets = tensor[1].unique()\n",
    "            i_grid, j_grid = torch.meshgrid(random_sample_tensor, unique_targets, indexing='ij')\n",
    "            i_vals = i_grid.flatten()\n",
    "            j_vals = j_grid.flatten()\n",
    "\n",
    "            existing_edges = result_tensor[:, 1:3]\n",
    "            max_node_id = max(i_vals.max().item(), j_vals.max().item(), existing_edges.max().item()) + 1\n",
    "\n",
    "            packed_existing = (existing_edges[:, 0] * max_node_id + existing_edges[:, 1])\n",
    "            packed_pairs = i_vals * max_node_id + j_vals\n",
    "\n",
    "            # Use torch.isin (vectorized, GPU) instead of slow CPU loop\n",
    "            exists = torch.isin(packed_pairs, packed_existing)\n",
    "            mask = ~exists & (i_vals != j_vals)\n",
    "            non_edges_pairs = torch.stack((i_vals[mask], j_vals[mask]), dim=1)\n",
    "\n",
    "            if non_edges_pairs.shape[0] > 0:\n",
    "                non_edges_tensor = torch.cat([\n",
    "                    torch.zeros((non_edges_pairs.shape[0], 1), device=self.device, dtype=torch.long),\n",
    "                    non_edges_pairs,\n",
    "                    torch.full((non_edges_pairs.shape[0], 1), edge_type1, device=self.device),\n",
    "                    torch.full((non_edges_pairs.shape[0], 1), edge_type2, device=self.device)\n",
    "                ], dim=1)\n",
    "            else:\n",
    "                non_edges_tensor = torch.empty((0, 5), dtype=torch.long, device=self.device)\n",
    "        else:\n",
    "            non_edges_tensor = torch.empty((0, 5), dtype=torch.long, device=self.device)\n",
    "\n",
    "        comb_r, comb_j = torch.combinations(random_sample_tensor, r=2).unbind(1)\n",
    "        r_venue = paper_venues[comb_r]\n",
    "        j_venue = paper_venues[comb_j]\n",
    "        unequal_mask = (r_venue != j_venue).flatten().nonzero(as_tuple=True)[0]\n",
    "\n",
    "        if unequal_mask.numel() > 0:\n",
    "            comb_r = comb_r[unequal_mask].squeeze()\n",
    "            comb_j = comb_j[unequal_mask].squeeze()\n",
    "            r_venue = r_venue[unequal_mask]\n",
    "            j_venue = j_venue[unequal_mask]\n",
    "\n",
    "            venue_non_edges = torch.cat([\n",
    "                torch.zeros((comb_r.shape[0]*2, 1), device=self.device, dtype=torch.long),\n",
    "                torch.cat([comb_r.unsqueeze(1), comb_j.unsqueeze(1)], dim=0),\n",
    "                torch.cat([j_venue, r_venue], dim=0),\n",
    "                torch.full((comb_r.shape[0]*2, 1), edge_entities['paper'], device=self.device),\n",
    "                torch.full((comb_r.shape[0]*2, 1), edge_entities['venue'], device=self.device)\n",
    "            ], dim=1)\n",
    "        else:\n",
    "            venue_non_edges = torch.empty((0, 5), dtype=torch.long, device=self.device)\n",
    "\n",
    "        data_matrix = torch.cat((result_tensor, non_edges_tensor, venues_tensor, venue_non_edges), dim=0)\n",
    "        return data_matrix, unique_tensor, random_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ba6e404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class LossFunction:\n",
    "    def __init__(self, alpha=1.0, eps=1e-8, use_regularization=False, lam=0.01, weight = 0.01):\n",
    "        \"\"\"\n",
    "        Initialize the loss function with given parameters.\n",
    "        \n",
    "        Args:\n",
    "            alpha (float): Scaling parameter for edge probability.\n",
    "            eps (float): Small value to prevent log(0).\n",
    "            use_regularization (bool): Whether to include Gaussian regularization.\n",
    "        \"\"\"\n",
    "        self.alpha = alpha\n",
    "        self.eps = eps\n",
    "        self.use_regularization = use_regularization\n",
    "        self.lam = lam\n",
    "        self.weight = weight\n",
    "\n",
    "    def edge_probability(self, z_i, z_j):\n",
    "        \"\"\"Compute the probability of an edge existing between two embeddings.\"\"\"\n",
    "        dist_sq = torch.sum((z_i - z_j) ** 2, dim=1)  # Squared Euclidean distance (batch-wise)\n",
    "        # return 1 / (1 + torch.exp(-self.alpha + dist_sq))  # Logistic function, element-wise\n",
    "        return torch.sigmoid(-dist_sq + self.alpha)\n",
    "\n",
    "    def link_loss(self, label, z_u, z_v):\n",
    "        \"\"\"Compute the loss for a single edge.\"\"\"\n",
    "        prob = self.edge_probability(z_u, z_v)  # Compute edge probabilities (batch-wise)\n",
    "        prob = torch.clamp(prob, self.eps, 1 - self.eps)  # Numerical stability\n",
    "\n",
    "        # Compute the loss for each edge\n",
    "        return label * torch.log(prob) + self.weight * (1 - label) * torch.log(1 - prob)\n",
    "\n",
    "    def compute_loss(self, z, datamatrix_tensor):\n",
    "        \"\"\"Compute the total loss for the dataset.\"\"\"\n",
    "        # Extract labels, u_idx, and v_idx in a vectorized way\n",
    "        labels = datamatrix_tensor[:, 0].float()\n",
    "        u_idx = datamatrix_tensor[:, 1].long()\n",
    "        v_idx = datamatrix_tensor[:, 2].long()\n",
    "        pv1_idx = datamatrix_tensor[:, 3].long()\n",
    "        pv2_idx = datamatrix_tensor[:, 4].long()\n",
    "\n",
    "        edge_entities = {\n",
    "            0: 'paper',\n",
    "            1: 'author',\n",
    "            2: 'institution',\n",
    "            3: 'field_of_study',\n",
    "            4: 'venue'\n",
    "        }\n",
    "\n",
    "        # Get embeddings for u_idx and v_idx\n",
    "        z_u = torch.stack([\n",
    "            z[edge_entities[j.item()]][i.item()]\n",
    "            for i, j in zip(u_idx, pv1_idx)\n",
    "        ])\n",
    "        z_v = torch.stack([\n",
    "            z[edge_entities[j.item()]][i.item()]\n",
    "            for i, j in zip(v_idx, pv2_idx)\n",
    "        ])\n",
    "\n",
    "        # Compute link loss for all edges in the batch\n",
    "        link_loss = self.link_loss(labels, z_u, z_v)  # shape (B,)\n",
    "\n",
    "        # Mean loss over the batch\n",
    "        loss = -torch.mean(link_loss)\n",
    "\n",
    "        # Optionally add regularization\n",
    "        if self.use_regularization:\n",
    "            regularization = self.lam * torch.sum(z ** 2)\n",
    "            loss += regularization\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e542d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeEmbeddingTrainer:\n",
    "    def __init__(self, device=None):        # Initialize input data, parameters, and setup\n",
    "        self.device = device or torch.device(\"cpu\")\n",
    "\n",
    "        # Optimizers\n",
    "        # self.optimizer = torch.optim.Adam([], lr=self.lr) # KOM TILBAGE\n",
    "\n",
    "        # Loss function (assumed to be defined elsewhere)\n",
    "        # self.loss_function = LossFunction(alpha=self.alpha, eps=self.eps, use_regularization=True, lam=self.lam)\n",
    "\n",
    "    def save_checkpoint(self, path):\n",
    "        checkpoint = {\n",
    "            'collected_embeddings': self.collected_embeddings.state_dict(),\n",
    "            'optimizer': self.optimizer.state_dict(),\n",
    "        }\n",
    "        torch.save(checkpoint, path)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_checkpoint(path, *args, **kwargs):\n",
    "        obj = NodeEmbeddingTrainer(*args, **kwargs)\n",
    "        checkpoint = torch.load(path)\n",
    "        obj.papernode_embeddings.load_state_dict(checkpoint['papernode_embeddings'])\n",
    "        obj.venuenode_embeddings.load_state_dict(checkpoint['venuenode_embeddings'])\n",
    "        obj.optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        obj.venue_optimizer.load_state_dict(checkpoint['venue_optimizer'])\n",
    "        obj.specific_papernode_indices = checkpoint['specific_papernode_indices']\n",
    "        obj.specific_venuenode_indices = checkpoint['specific_venuenode_indices']\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af458264",
   "metadata": {},
   "outputs": [],
   "source": [
    "### paper_c_paper_train\n",
    "num_papers = 200     # total number of papers (IDs from 0 to 749999)\n",
    "num_edges = 1000        # number of citation edges\n",
    "\n",
    "# Randomly generate citing and cited paper IDs\n",
    "citing = torch.randint(0, num_papers, (num_edges,))\n",
    "cited = torch.randint(0, num_papers, (num_edges,))\n",
    "\n",
    "# Stack to form a 2 x num_edges tensor\n",
    "paper_c_paper_train = torch.stack([citing, cited])\n",
    "\n",
    "### data and venue_value\n",
    "\n",
    "# Generate a tensor of N random integers between 0 and 50\n",
    "num_values = num_papers  # You can change this number\n",
    "random_values = torch.randint(0, 51, (num_values, 1))\n",
    "\n",
    "# Create the dictionary\n",
    "data = {\n",
    "    'y_dict': {\n",
    "        'paper': random_values\n",
    "    }\n",
    "}\n",
    "\n",
    "tensor_values = data['y_dict']['paper']\n",
    "venue_value = {i: tensor_values[i] for i in range(tensor_values.size(0))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f235949",
   "metadata": {},
   "outputs": [],
   "source": [
    "### data and venue_value\n",
    "\n",
    "# Generate a tensor of N random integers between 0 and 50\n",
    "num_values = num_papers  # You can change this number\n",
    "random_values = torch.randint(0, 51, (num_values, 1))\n",
    "\n",
    "# Create the dictionary\n",
    "data = {\n",
    "    'y_dict': {\n",
    "        'paper': random_values\n",
    "    }\n",
    "}\n",
    "\n",
    "tensor_values = data['y_dict']['paper']\n",
    "venue_value = {i: tensor_values[i] for i in range(tensor_values.size(0))}\n",
    "\n",
    "venues_values = torch.unique(data['y_dict']['paper'])\n",
    "\n",
    "collected_embeddings = {\n",
    "    'paper': {},\n",
    "    'venue': {}\n",
    "}\n",
    "\n",
    "embedding_dim = 2\n",
    "a = -100\n",
    "b = -a\n",
    "# Venue embeddings\n",
    "embed = torch.nn.Embedding(len(venues_values), embedding_dim)\n",
    "torch.nn.init.uniform_(embed.weight, a, b)\n",
    "\n",
    "venue_id_to_idx = {venue_id.item(): idx for idx, venue_id in enumerate(venues_values)}\n",
    "\n",
    "indices = torch.tensor([venue_id_to_idx[venue_id.item()] for venue_id in venues_values], dtype=torch.long)\n",
    "embeddings = embed(indices)\n",
    "\n",
    "for venue_id in venues_values:\n",
    "    collected_embeddings['venue'][venue_id.item()] = embeddings[venue_id_to_idx[venue_id.item()]]\n",
    "\n",
    "# Paper embeddings\n",
    "unique_paper_ids = torch.unique(paper_c_paper_train)\n",
    "embed = torch.nn.Embedding(len(unique_paper_ids), embedding_dim)\n",
    "torch.nn.init.uniform_(embed.weight, a, b)\n",
    "paper_id_to_idx = {pid.item(): idx for idx, pid in enumerate(unique_paper_ids)}\n",
    "\n",
    "indices = torch.tensor([paper_id_to_idx[pid.item()] for pid in paper_c_paper_train.flatten()], dtype=torch.long)\n",
    "embeddings = embed(indices)\n",
    "\n",
    "for pid, emb in zip(paper_c_paper_train.flatten(), embeddings):\n",
    "    collected_embeddings['paper'][pid.item()] = emb\n",
    "\n",
    "if collected_embeddings:\n",
    "    torch.save(collected_embeddings, f\"/mnt/c/Users/Bruger/Desktop/Bachelor/GraphML_Bachelorprojekt/dataset/ogbn_mag/processed/collected_embeddings_{embedding_dim}_spread_{b}_synt.pt\")\n",
    "    print(\"embeddings saved\")\n",
    "\n",
    "\n",
    "# Load the collected embeddings dictionary\n",
    "collected_embeddings = torch.load(f\"/mnt/c/Users/Bruger/Desktop/Bachelor/GraphML_Bachelorprojekt/dataset/ogbn_mag/processed/collected_embeddings_{embedding_dim}_spread_{b}_synt.pt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f585520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_209270/21776103.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  collected_embeddings = torch.load(f\"/mnt/c/Users/Bruger/Desktop/Bachelor/GraphML_Bachelorprojekt/dataset/ogbn_mag/processed/collected_embeddings_{embedding_dim}_spread_{b}_synt.pt\")\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a717ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dict = collected_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7eeede4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "starting\n",
      "Epoch 1/1\n",
      "Loss: 2.642009973526001\n",
      "Loss: 2.973162889480591\n",
      "Loss: 2.921341896057129\n",
      "Loss: 2.777721643447876\n",
      "Loss: 2.631525754928589\n",
      "Loss: 2.912360429763794\n",
      "Loss: 2.7863221168518066\n",
      "Loss: 2.8194921016693115\n",
      "Loss: 3.055563449859619\n",
      "Loss: 2.7700271606445312\n",
      "Loss: 2.959388494491577\n",
      "Loss: 2.9187705516815186\n",
      "Loss: 2.8522348403930664\n",
      "Loss: 2.801301956176758\n",
      "Loss: 2.9689011573791504\n",
      "Loss: 2.7890467643737793\n",
      "Loss: 2.887988328933716\n",
      "Loss: 3.0414206981658936\n",
      "Loss: 2.859528064727783\n",
      "Loss: 2.8570852279663086\n",
      "Loss: 2.720592975616455\n",
      "Loss: 2.649127960205078\n",
      "Loss: 2.8607873916625977\n",
      "Loss: 3.0326731204986572\n",
      "Loss: 3.231698751449585\n",
      "Loss: 2.7435061931610107\n",
      "Loss: 2.8153586387634277\n",
      "Loss: 2.804795026779175\n",
      "Loss: 4.792372703552246\n",
      "No more nodes to process. Exiting.\n",
      "[2.642009973526001, 2.973162889480591, 2.921341896057129, 2.777721643447876, 2.631525754928589, 2.912360429763794, 2.7863221168518066, 2.8194921016693115, 3.055563449859619, 2.7700271606445312, 2.959388494491577, 2.9187705516815186, 2.8522348403930664, 2.801301956176758, 2.9689011573791504, 2.7890467643737793, 2.887988328933716, 3.0414206981658936, 2.859528064727783, 2.8570852279663086, 2.720592975616455, 2.649127960205078, 2.8607873916625977, 3.0326731204986572, 3.231698751449585, 2.7435061931610107, 2.8153586387634277, 2.804795026779175, 4.792372703552246]\n",
      "loss_epoch: 2.926762284903691\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import copy\n",
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "batch_size = 7\n",
    "num_epochs = 1\n",
    "lr = 0.1\n",
    "alpha = 0.1\n",
    "lam = 0.01\n",
    "embedding_dim = 2\n",
    "\n",
    "loss_function = LossFunction()\n",
    "N_emb = NodeEmbeddingTrainer()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "print(\"starting\")\n",
    "\n",
    "\n",
    "citation_dict = defaultdict(list)\n",
    "for src, tgt in zip(paper_c_paper_train[0], paper_c_paper_train[1]):\n",
    "    citation_dict[src.item()].append(tgt.item())\n",
    "\n",
    "all_papers = list(citation_dict.keys())\n",
    "\n",
    "num_iterations = int(len(embed_dict['venue']) + len(embed_dict['paper'])) # we need to be able to look at the complete dataset\n",
    "\n",
    "# num_iterations = 2\n",
    "\n",
    "\n",
    "params = []\n",
    "for subdict in embed_dict.values():\n",
    "    params.extend(subdict.values())\n",
    "loss_pr_epoch = []\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    print(f\"Epoch {i + 1}/{num_epochs}\")\n",
    "    l_prev = list(paper_c_paper_train.unique().numpy())  # Initial list of nodes\n",
    "    optimizer = torch.optim.Adam(params, lr=lr)\n",
    "    loss_pr_iteration = []\n",
    "\n",
    "    # import time\n",
    "    # start = time.time()\n",
    "    # dm, unique_list, random_sample = mini_b.data_matrix()\n",
    "    # print(\"Batch gen time:\", time.time() - start)\n",
    "\n",
    "    mini_b = mini_batches_fast(paper_c_paper_train, l_prev, batch_size, ('paper', 'cites', 'paper'), data, citation_dict, all_papers)\n",
    "\n",
    "    for j in range(num_iterations):\n",
    "        mini_b.set_unique_list(l_prev)  # Update only the node list\n",
    "        dm, l_next, random_sample = mini_b.data_matrix()\n",
    "        # print(dm)\n",
    "\n",
    "    # for j in range(num_iterations):\n",
    "\n",
    "        # Generate mini-batches\n",
    "        # mini_b = mini_batches_fast(paper_c_paper_train, l_prev, batch_size, ('paper', 'cites', 'paper'), data)\n",
    "        # dm, l_next, random_sample = mini_b.data_matrix()\n",
    "\n",
    "        # Move data to GPU\n",
    "        dm = dm.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function.compute_loss(embed_dict, dm)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Loss: {loss.detach().item()}\")\n",
    "        # Update node list for the next iteration\n",
    "        loss_pr_iteration.append(loss.detach().item())\n",
    "\n",
    "        l_prev = l_next\n",
    "        \n",
    "\n",
    "        if len(l_next) == 0:\n",
    "            print(\"No more nodes to process. Exiting.\")\n",
    "            print(loss_pr_iteration)\n",
    "            loss_pr_epoch.append(np.mean(loss_pr_iteration))\n",
    "            print(f\"loss_epoch: {loss_pr_epoch[i]}\")\n",
    "            break\n",
    "\n",
    "        # Cleanup\n",
    "        if (i + 1) % 5 == 0:  # Or do it every iteration if memory is super tight\n",
    "            import gc\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b28c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "venues_values = torch.unique(data['y_dict']['paper'])\n",
    "\n",
    "collected_embeddings = {\n",
    "    'paper': {},\n",
    "    'venue': {}\n",
    "}\n",
    "\n",
    "embedding_dim = 2\n",
    "a = -100\n",
    "b = -a\n",
    "# Venue embeddings\n",
    "embed = torch.nn.Embedding(len(venues_values), embedding_dim)\n",
    "torch.nn.init.uniform_(embed.weight, a, b)\n",
    "\n",
    "venue_id_to_idx = {venue_id.item(): idx for idx, venue_id in enumerate(venues_values)}\n",
    "\n",
    "indices = torch.tensor([venue_id_to_idx[venue_id.item()] for venue_id in venues_values], dtype=torch.long)\n",
    "embeddings = embed(indices)\n",
    "\n",
    "for venue_id in venues_values:\n",
    "    collected_embeddings['venue'][venue_id.item()] = embeddings[venue_id_to_idx[venue_id.item()]]\n",
    "\n",
    "# Paper embeddings\n",
    "unique_paper_ids = torch.unique(paper_c_paper_train)\n",
    "embed = torch.nn.Embedding(len(unique_paper_ids), embedding_dim)\n",
    "torch.nn.init.uniform_(embed.weight, a, b)\n",
    "paper_id_to_idx = {pid.item(): idx for idx, pid in enumerate(unique_paper_ids)}\n",
    "\n",
    "indices = torch.tensor([paper_id_to_idx[pid.item()] for pid in paper_c_paper_train.flatten()], dtype=torch.long)\n",
    "embeddings = embed(indices)\n",
    "\n",
    "for pid, emb in zip(paper_c_paper_train.flatten(), embeddings):\n",
    "    collected_embeddings['paper'][pid.item()] = emb\n",
    "\n",
    "if collected_embeddings:\n",
    "    torch.save(collected_embeddings, f\"/mnt/c/Users/Bruger/Desktop/Bachelor/GraphML_Bachelorprojekt/dataset/ogbn_mag/processed/collected_embeddings_{embedding_dim}_spread_{b}_synt.pt\")\n",
    "    print(\"embeddings saved\")\n",
    "\n",
    "\n",
    "# Load the collected embeddings dictionary\n",
    "collected_embeddings = torch.load(f\"/mnt/c/Users/Bruger/Desktop/Bachelor/GraphML_Bachelorprojekt/dataset/ogbn_mag/processed/collected_embeddings_{embedding_dim}_spread_{b}_synt.pt\")\n",
    "\n",
    "embed_dict = collected_embeddings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelor10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
